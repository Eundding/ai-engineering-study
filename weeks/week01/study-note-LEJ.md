

AI 애플리케이션에 대한 수요는 증가한 반면 AI 애플리케이션을 만드는 진입 장벽은 낮아졌다. 이로 인해 쉽게 사용할 수 있는 모델들을 기반으로 애플리케이션을 만드는 과정인 AI 엔지니어링은 엔지니어링 분야 중 가장 빠르게 성장하는 분야가 되었다.

이 장에서는 **AI 엔지니어링의 폭발적인 성장의 원동력인 파운데이션 모델의 개요**를 시작으로 **다양한 성공적인 AI 활용 사례**, **AI가 잘하는 것과 아직 부족한 것**을 설명한다.

---
# AI 엔지니어링의 부상
파운데이션 모델은 대규모 언어 모델에서 나왔고, 대규모 언어 모델은 단순한 언어 모델에서 비롯되었다. 언어 모델이 AI 엔지니어링으로 진화하는 데 핵심이 된 중요한 발전들을 살펴보자.

## 언어 모델에서 대규모 언어 모델로
언어 모델은 예전부터 존재했지만, **자기 지도 학습(self-supervised learning)** 덕분에 오늘날과 같은 규모로 성장할 수 있었다.

### 언어 모델(language model)
- 하나 이상의 언어에 대한 통계 정보를 인코딩
- 언어 모델의 기본 단위는 토큰이다. 토큰은 모델에 따라 문자, 단어, 또는 단어의 일부(ex. -tion)가 될 수 있다.
![](https://velog.velcdn.com/images/dkan9634/post/87b34be2-344b-4aa3-9fcb-54f42d73d9f9/image.png)
- 토큰화(tokenization): 원문을 모델이 정한 길이로 나누는 과정 
   - GPT-4: 토큰 하나의 평균 길이는 단어의 약 3/4, 따라서 100 토큰은 약 75개 단어
- **어휘(vocabulary)** : 모델이 다룰 수 있는 모든 토큰의 집합은 모델

> **언어모델은 왜 단어나 문장이 아닌 토큰을 사용할까?**
1. 토큰은 단어를 의미 있는 구성 요소로 나눌 수 있다.
(ex. '요리하기' -> '요리'+'하기' 모두 원래 단어의 일부 의미 담고 있다.)
2. 고유한 토큰의 수가 고유한 단어의 수보다 적기 때문에 어휘 크기가 줄어들어 모델이 더 효율적이다.
3. 토큰은 모델이 알려지지 않은 단어를 처리할 때도 도움을 준다. 토큰은 단어보다 단위가 적으면서도 개별 문자보다 더 많은 의미를 유지한다.
(ex. 'chatgpting' -> 'chatgpt'+'-ing') 


언어 모델에는 두 가지(토큰을 예측할 때 사용할 수 있는 정보에 따라 구분)
1. 마스크 언어 모델
2. 자기회귀 언어 모델

#### 마스크 언어 모델(masked language model)
- 누락된 토큰 전후 컨텍스트를 사용해 시퀀스의 어느 위치에서든 **누락된 토큰을 예측**하도록 학습
- 기본적으로 빈칸을 채울 수 있도록 학습
- **감정 분석**이나 **텍스트 분류**처럼 새로운 텍스트를 만들지 않는 작업에 주로 사용된다.
**코드 디버깅**처럼 모델이 앞뒤 코드를 모두 이해해서 오류를 찾아야 하는 전체적인 컨텍스트 이해가 필요한 작업에도 유용
- ex) BERT

#### 자기회귀 언어 모델(autoregressive language model)
- 이전 토큰들만 보고 시퀀스의 다음 토큰을 예측하도록 학습
- 토큰을 하나씩 순차적으로 생성할 수 있고 텍스트 생성 분야의 대세로 자리 잡아 마스크 언어 모델보다 훨씬 더 큰 인기
![](https://velog.velcdn.com/images/dkan9634/post/ca008c41-eba3-4822-89d7-a0c0efdaf4c2/image.png)

정해진 답 없이 개방형 출력을 생성하는 모델을 생성 모델(generative model)이라고 부르는데, 바로 여기에서 **생성형 AI(generative AI)**라는 용어가 유래됐다.

언어 모델은 텍스트(프롬프트)가 주어지면 해당 텍스트를 완성하려는 일종의 완성 기계로 생각하면 된다. 완성된 결과가 확률에 기반한 예측이며, 정확성이 보장되지 않는다.

### 자기 지도 학습(self-supervised learning)
언어 모델링은 수많은 ML 알고리즘 중 하나일 뿐이다. 언어 모델링 외에도 객체 탐지, 토픽 모델링, 추천 시스템, 일기 예보, 주가 예측 등을 위한 모델들도 있다.

언어 모델에 어떤 특별한 점이 있기에 챗GPT 시대를 연 규모 확장 접근법의 핵심이 될 수 있었을까?
-> 많은 다른 모델이 지도 학습(supervise learning)을 필요로 하는 반면, **언어 모델은 자기 지도 학습(self-supervise learning)**으로 학습할 수 있다는 점

- 데이터 레이블링 병목 현상을 극복해 모델이 학습할 수 있는 더 큰 데이터셋을 만들 수 있게 해주므로, 모델의 규모를 효과적으로 키울 수 있다.
    - 지도 학습의 단점은 데이터 레이블링에 많은 비용과 시간이 소요된다. 
- 명시적인 레이블이 필요하지 않고 모델이 입력 데이터에서 추론할 수 있다.
- 언어 모델링은 각 입력 시퀀스가 레이블(예측할 토큰)과 모델이 이런 레이블을 예측하는 데 사용할 수 있는 컨텍스트를 모두 제공하기 때문에 자기 지도 학습이 가능하다.
- 시퀀스 시작, 끝 표시하는데 특히 시퀀스 종료 마커는 언어 모델이 응답을 끝낼 시점을 알 수 있게 해주기 때문에 중요하다.
 
+) 자기 지도 학습과 비지도 학습은 다르다. **자기 지도 학습은 입력 데이터에서 레이블을 추론하지만 비지도 학습은 레이블이 전혀 필요하지 않다.**

- 자기 지도 학습은 언어 모델이 레이블링 없이도 텍스트 시퀀스를 통해 학습할 수 있다. 텍스트 시퀀스는 어디에나 존재해서 방대한 양의 학습 데이터를 구축할 수 있고 이를 통해 언어 모델을 LLM으로 확장할 수 있다.

**언어 모델이 얼마나 커야 대규모(large)로 간주될 수 있을까?**
-> 오늘 대규모로 여겨져도 내일이면 아주 작게 여겨질 수 있다. **모델의 크기는 일반적으로 파라미터의 수**로 측정된다.
-> 2018년 6월 첫 GPT param수 : 1억 1700만 개
-> 2019년 2월 GPT-2 param 수 : 15억 개
+) 지금은 1000억 개의 파라미터를 가진 모델을 대규모로 본다.(언젠가 소규모로 여겨질 수도)

당연하게 여길 수 있지만,** 더 큰 모델은 왜 더 많은 데이터가 필요**할까?
-> **모델이 클수록 학습할 수 있는 용량이 커지므로 성능을 극대화하려면 더 많은 학습 데이터가 필요**하다. 큰 모델을 작은 데이터셋으로 학습할 수 있지만, 컴퓨팅 자원 낭비일 뿐

---
## 대규모 언어 모델에서 파운데이션 모델로
- 사람은 언어뿐만 아니라 시각, 청각, 촉각 등을 통해서도 세상을 인식한다. 따라서 AI가 실제 세상에서 유의미하게 작동하기 위해서는 글자 이상의 데이터를 처리하는 능력이 꼭 필요하다.
- 이런 이유로 언어 모델은 더 많은 데이터 모달리티를 포함하도록 확장되고 있다. 
(GPT-4V와 클로드3은 이미지와 텍스트를 이해할 수 있고 일부 모델은 동영상, 3D 에셋, 단백질 구조 등을 이해하기도 한다.)
- 많은 사람이 여전히 제미나이와 GPT-4V를 LLM이라 부르지만, 이것들은 '파운데이션 모델(foundation model)'로 설명하는 것이 더 적절하다.
> **파운데이션**이라는 단어는 이 모델들이 AI 애플리케이션에서 갖는 중요성과 다양한 요구사항에 맞게 발전시킬 수 있다는 사실을 의미

- 둘 이상의 데이터 형태를 처리할 수 있는 모델은 멀티모달 모델이다.
생성형 멀티모달 모델은 대규모 멀티모달 모델(large multimodal model, LMM)
- 언어 모델이 텍스트 토큰에 기반해 토큰을 생성할 때, 멀티모달 모델은 텍스트와 이미지 토큰, 또는 모델이 지원하는 다른 모달리티를 기반으로 다음 토큰을 생성한다.
![](https://velog.velcdn.com/images/dkan9634/post/610c2536-7a31-4e8d-9f5a-119bd89d0a52/image.png)
- 자기 지도 학습은 멀티모달 모델에서도 효과가 있다.
- 오픈 AI는 **자연어 지도**(natural language supervision)라는 자기 지도 의 변형을 사용해 언어 이미지 모델 **CLIP**(OpenAI, 2021)을 학습했다.
     - 각 이미지에 대한 레이블을 수동으로 생성하는 대신 **인터넷에서 (이미지, 텍스트) 쌍을 수집**했다. 
     - 그 결과 수동 레이블링 비용 없이 이미지넷보다 400배 더 큰 4억 개의 (이미지, 텍스트) 쌍으로 구성된 데이터셋을 생성할 수 있었다. 
     - 이 데이터셋 덕분에 **CLIP은 사상 최초로 추가 학습 없이도 여러 이미지 분류 작업을 일반화**

- 파운데이션 모델은 규모와 학습 방식 덕분에 다양한 작업을 수행할 수 있다.
(하나의 LLM으로 감정 분석과 번역 모두 수행)
- 특정 작업에 대한 성능을 올리고 싶다면 **파인튜닝(fine-tuning)**이 필요

#### 모델이 원하는 결과물을 내놓도록 유도하는 기법
1. 프롬프트 엔지니어링(prompt engineering)
- 원하는 설명 예시와 함께 상세한 지시를 모델에 제공
2. 검색 증강 생성(retrieval-augmented generation, RAG)
- 데이터베이스를 활용해 지시를 보완하는 것
- ex. 고객 리뷰 데이터베이스에 연결해 더 나은 설명 생성
3. 추가로 파인튜닝
- 고품질의 제품 설명 데이터셋을 사용해 모델을 추가로 파인튜닝

책에서는 파운데이션 모델의 장점만 언급했으나 작업 특화(task-specific) 모델도 장점이 있다. 보통 더 작아서 빠르고 저렴하게 사용할 수 있다.

---
## 파운데이션 모델에서 AI 엔지니어링으로
- AI 엔지니어링은 파운데이션 모델을 기반으로 애플리케이션을 만드는 과정
- 그러나 이미 사람들은 10년이 넘게 AI 애플리케이션을 만들어 왔다. 이 과정은 ML 엔지니어링 또는 MLOps(machine learning operations의 약자)라고 불려 왔다. 

왜 지금 AI 엔지니어링이라는 용어를 사용하게 된 걸까?
-> 전통적인 ML 엔지니어링이 모델 자체를 개발하는 것이라면, AI 엔지니어링은 이미 존재하는 모델을 활용한다. 강력한 파운데이션 모델의 이용 가능성과 접근성은 AI 엔지니어링의 빠른 성장을 위한 이상적인 조건을 만드는 **세 가지 요인**으로 이어진다.

1. 범용 AI 능력
- 파운데이션 모델은 더 많은 작업을 수행할 수 있기 때문에 능력이 뛰어나다.
- 이전에 불가능하다고 여겨졌던 애플리케이션 서비스가 이제는 가능해졌다.
2. AI 투자 증가
3. AI 애플리케이션 개발에 대한 낮아진 진입 장벽

![](https://velog.velcdn.com/images/dkan9634/post/be72219d-64e7-4784-a65f-6d0dc49b0fa0/image.png)

---
# 파운데이션 모델 활용 사례
![](https://velog.velcdn.com/images/dkan9634/post/1ff0dbed-164f-4457-9eee-dff39341934c/image.png)
![](https://velog.velcdn.com/images/dkan9634/post/7918aefb-a320-49ea-b126-32a309b52485/image.png)

### 코딩
- 일반적인 코딩을 돕는 도구 외에도 특정 코딩 작업에 특화된 도구가 많이 있다.
ex) 웹 페이지와 PDF에서 구조화된 데이터를 추출하기(AgentGPT)
자연어를 코드로 변환하기(DB-GPT, SQL chat, PandasAI)
디자인이나 스크린샷을 주면, 주어진 이미지처럼 보이는 웹사이트로 변환할 코드 생성하기(screenshot-to-code, draw-a-ui)
하나의 프로그래밍 언어나 프레임워크에서 다른 것으로 번역하기(GPT-Migrate, AI Code Translator)
문서 작성하기(Autodoc)
테스트 만들기(PentestGPT)
커밋 메시지 만들기(AI Commits)
- 맥킨지 연구원들은 AI가 개발자의 문서화 생산성을 2배로, 코드 생성과 코드 리팩터링 생산성을 25~50% 높일 수 있다는 것을 발견했다.
- AI는 백엔드보다 프론트앤드 개발에서 더 뛰어난 성능을 발휘한다.
- AI는 간단한 작업에서 개발자의 생산성을 크게 향상시킬 수 있지만, 매우 복잡한 작업에는 그 효과가 미미

### 이미지 및 동영상 제작
### 글쓰기
### 교육
### 대화형 봇
### 정보 집계
### 데이터 체계화
### 워크플로 자동화
- AI의 궁극적인 목표는 가능한 한 많은 영역을 자동화하는 것
- 많은 작업을 수행하려면 외부 도구에 접근 필요하다. (ex. 레스토랑 예약하기 위해 검색 엔진 열어 전화번호 찾고, 일정을 캘린더에 추가할 수 있는 권한 등)
이때 스스로 계획을 세우고 도구를 사용할 수 있는 AI를 **에이전트**라고 한다.

---
# AI 애플리케이션 기획
## 활용 사례 평가
- 가장 먼저 해야할 질문은 AI 애플리케이션을 **왜** 만들고 싶은지다.

### 애플리케이션에서 AI와 사람의 역할
- AI 제품에서 AI가 맡는 역할에 따라 애플리케이션의 개발 방식과 요구사항이 달라진다.
- 핵심적 또는 보완적
    - 앱이 AI 없이도 작동할 수 있다면 AI는 그 앱에 보완적이다.
    - 애플리케이션에서 AI가 핵심적일수록 AI 부분이 더 정확하고 신뢰할 수 있어야 한다. AI가 애플리케이션의 핵심이 아닐 때 사람들은 실수에 좀 더 관대하다.

- 반응형 또는 선제형
	- 반응형: 사용자의 요청이나 특정 행동에 응답하는 방식
   즉시 응답해야 하므로 지연시간이 짧아야 한다.
ex) 챗봇
    - 선제형: 사용자에게 유용하다고 판단되는 적절한 시점에 먼저 정보를 제시
결과를 미리 계산해 두었다가 적절한 때에 보여줄 수 있기에, 지연 시간의 중요성이 상대적으로 덜하다. 품질이 낮으면 불필요하게 느껴질 수 있다. 
ex) 구글 맵스의 교통 알림
- 동적 또는 정적
    - 동적 방식은 사용자 피드백으로 지속적으로 업데이트 ex) Face ID
    - 정적 방식은 주기적으로만 업데이트 ex)  구글포토의 객체 탐지 모델
    - AI 맥락에서 동적 방식이란, 각 사용자가 자신의 데이터로 모델을 계속 파인튜닝하며 자신만의 모델을 갖게 되는 것 ex) chatGPT의 메모리 기능
    - 반면, 정적 방식에서는 여러 사용자가 하나의 공유 모델을 함께 사용

AI의 의사결정 과정에 사람을 참여시키는 것을 휴먼 인 더 루프(human-in-the-loop)라고 한다.

마이크로소프트는 2023년에 제품의 AI 자동화를 점진적으로 증가시키기 위한 프레임워크로 **크롤-워크-런(crawl-walk-run)**을 제안했다.
1. **크롤**은 사람의 참여가 필수
2. **워크**는 AI가 내부 직원과 직접 상호작용할 수 있음을 의미
3. **런**은 잠재적으로 외부 사용자와의 직접적인 AI 상호작용을 포함해 자동화가 향상됨을 의미한다.

### AI 제품 방어 가능성
- AI 애플리케이션을 독립형 제품으로 판매한다면 방어 가능성(defensibility)을 고려하는 것이 중요하다.
- 낮은 진입 장벽은 축복이자 저주다.(내가 쉽게 만들면 다른 사람도 쉽게 만든다.)
- 파운데이션 모델 위에 애플리케이션을 만든다는 건 모델들 위에 하나의 계층을 얹는 셈이다. 이는 파운데이션 모델의 성능이 좋아지면 우리가 제공하는 계층이 모델에 흡수되어 애플리케이션이 쓸모없게 될 수 있다는 것을 의미한다.
- AI 분야의 경쟁 우위는 **기술력, 데이터, 유통력**

## 기대치 설정
- AI 애플리케이션을 직접 개발하기로 결정했다면, 다음 단계는 성공이 어떤 모습일지 파악하는 것이다.
- 가장 중요한 지표는 AI 애플리케이션이 비즈니스에 어떤 영향을 미칠지이다.
- ex) 챗봇 성능 기준으로 다음과 같은 지표군이 포함될 수 있다.
    - TTFT(첫 토큰까지 걸리는 시간), TPOT(출력 토큰당 시간) 등
    
## 마일스톤 계획

## 유지보수
- 제품 기획은 목표 달성에서 끝나지 않고 달성 후 이 제품이 시간이 지나면서 어떻게 변할 수 있고 어떻게 유지보수해야 할지도 생각해야 한다.
- AI 추론 비용은 시간이 지나면서 급격히 감소한다.![](https://velog.velcdn.com/images/dkan9634/post/507bedf6-568b-42fa-bc20-e7dc03d3ac41/image.png)

---
# AI 엔지니어링 스택
- AI 엔지니어링을 제대로 이해하려면 우선 AI 엔지니어링이 ML 엔지니어링에서 발전했다는 점을 인식하는 것이 중요하다.

## AI의 세 가지 계층
모든 AI 애플리케이션 스택에는 가장 상위부터 애플리케이션 개발, 모델 개발, 인프라 계층이 있다. 개발할 땐 최상위 계층에서 시작해 필요에 따라 아래로 내려간다.

### 애플리케이션 개발
- 모델에 적절한 프롬프트와 필요한 컨텍스트를 제공하는 것을 포함
- 철저한 평가와 좋은 인터페이스 필요

### 모델 개발
- 모델링, 학습, 파인튜닝, 추론 최적화를 위한 프레임워크를 포함해 모델을 개발하기 위한 도구 제공
- 데이터가 모델 개발의 핵심이므로 데이터셋 엔지니어링도 포함
- 역시 철저한 평가 필요

### 인프라
- 맨 아래에는 모델 서빙, 데이터와 컴퓨팅 관리, 모니터링을 위한 도구를 포함하는 인프라

![](https://velog.velcdn.com/images/dkan9634/post/76a0a928-ce58-4880-92c4-6366a8f7707e/image.png)

![](https://velog.velcdn.com/images/dkan9634/post/ec3b9c10-2638-4040-9d86-6f5d9ae700e3/image.png)
-> 2023년엔 스테이블 디퓨전과 챗GPT가 도입된 후 AI 도구의 수가 크게 증가
-> 2023년에 가장 높은 증가율을 보인 범주는 애플리케이션과 AI 엔지니어링

- 전통적인 ML 엔지니어링에서는 다양한 하이퍼파라미터로 실험
- 파운데이션 모델에서는 서로 다른 모델, 프롬프트, 검색 알고리즘, 샘플링 변수 등으로 실험한다.
- 모델을 빠르고 저렴하게 실행하고, 애플리케이션을 반복적으로 개선하기 위해 피드백 루프를 구축하는 것도 중요하다.

## AI 엔지니어링 vs ML 엔지니어링
- 파운데이션 모델을 사용한 애플리케이션 개발은 전통적인 ML 엔지니어링과 다음 세 가지 측면에서 차이가 있다.
1. 전통적인 ML: 파운데이션 모델X, 필요한 모델 직접 학습
AI 엔지니어링: 다른 사람이 학습시켜 놓은 모델을 가져다 쓰고 모델링과 학습보다는 모델 조정에 더 초점
2. AI 엔지니어링: 더 크고 더 많은 컴퓨팅 자원 소비, 더 높은 지연 시간을 발생시키는 모델을 다룸, 효율적인 학습과 추론 최적화에 대한 압박이 더 큼. 그 결과 GPU와 대규모 클러스터를 다룰 줄 아는 엔지니어에 대한 수요 역시 늘어남
3. AI 엔지니어링: 개방형 출력을 생성할 수 있는 모델을 다룸. 개방형 출력은 유연성을 제공하지만 그만큼 평가하기가 더 어렵다. 이는 평가가 AI 엔지니어링에서 훨씬 더 큰 문제가 된다는 의미

> AI 엔지니어링은 모델 개발보다는 **모델 조정과 평가에 더 중점**을 둔다는 점에서 ML 엔지니어링과 차이가 있다.

모델 조정 기법은 모델 가중치 업데이트 여부에 따라 두 가지 범주
1. **프롬프트 엔지니어링을 포함한 프롬프트 기반 기법은 모델 가중치를 업데이트하지 않고도 모델의 동작을 조정**
- 모델 자체를 바꾸는 대신 지시와 컨텍스트를 제공하여 모델의 반응을 원하는 방향으로 유도하는 것
- 프롬프트 엔지니어링은 비교적 쉽게 시작할 수 있고 데이터도 거의 필요 없다는 장점
- 하지만 복잡한 작업이나 성능에 대한 엄격한 기준이 있는 애플리케이션이라면, 프롬프트 엔지니어링만으로는 충분하지 않을 수 있다.

2. **파인튜닝은 모델 가중치를 업데이트 해야한다.**
- 모델 자체를 변경해 새로운 작업에 맞게 조정한다.
- 파인튜닝은 더 복잡하고 더 많은 데이터가 필요하지만 모델의 품질, 지연 시간, 비용을 크게 개선할 수 있다.
- 복잡한 작업에는 파인튜닝 기법이 많이 활용된다.

### 모델 개발
- 전통적인 ML 엔지니어링과 가장 밀접하게 연관된 계층
- 모델링과 학습, 데이터셋 엔지니어링, 추론 최적화라는 세가지 구성 요소가 있다.

#### 모델링과 학습
- 모델 아키텍처를 고안하고 학습하고 파인튜닝하는 과정
ex) 구글의 텐서플로, 허깅페이스의 트랜스포머, 메타의 파이토치
- ML 모델을 개발하려면 전문적인 ML 지식(클러스터링, 협업 필터링 같은 다양한 ML 알고리즘과 피드포워드, 합성곱, 트랜스포머와 같은 신경망 아키텍처 그리고 경사하강법, 손실 함수 등의 개념을 포함해 모델이 어떻게 학습하는지)
- 파운데이션 모델을 사용할 수 있게 되면서 AI 애플리케이션을 개발하는 데 ML 지식이 더 이상 필수가 아니게 됐지만 여전히 ML 지식은 매우 가치가 있다. 사용할 수 있는 도구의 폭을 넓혀주고 모델이 예상대로 작동하지 않을 때 문제를 해결하는 데 도움이 된다.


**사전학습**
- 모델을 처음부터 학습하는 것, 모델 가중치가 무작위로 초기화
- 압도적으로 가장 많은 자원 필요, 많은 시간 필요

**파인튜닝**
- 이미 학습된 모델을 추가로 학습하는 것
- 모델 가중치는 이전 학습 과정에서 얻어진 값
- 사전학습보다 적은 자원

**사후 학습**
- 파인튜닝과 거의 같은 과정이다.
- 업계에서는 두 용어 구분하는데 보통 '누가'학습을 수행하는지를 기준으로 삼는다.
- 모델 제공업체가 수행하면 사후 학습, 애플리케이션 개발자가 수행하면 파인튜닝

+) 프롬프트 엔지니어링을 하면서 이를 파인튜닝이라고 부르면 엄연히 틀림

#### 데이터셋 엔지니어링
- AI 모델의 학습과 조정에 필요한 데이터를 선별하고 생성하며 주석을 다는 것
- 전통적인 ML 엔지니어링에서 대부분의 활용 사례는 '폐쇄형'으로, 모델의 출력은 미리 정의된 값들 중 하나만 될 수 있다. ex) 스팸 분류
- 하지만 파운데이션 모델은 개방형이다.(개방형 질의에 주석을 다는 게 폐쇄형에 주석을 다는 것보다 훨씬 어렵고 이메일이 단순히 스팸인지 구분하는 것보다 글을 쓰는 것이 더 어렵다.)
- ML 엔지니어링: 정형 데이터, 파운데이션 모델을 이용한 AI 엔지니어링: 비정형 데이터
- 파인튜닝은 프롬프트 엔지니어링보다 더 많은 데이터가 필요하다.

#### 추론 최적화(Inference optimization)
- 모델을 더 빠르고 저렴하게 만드는 것
- 파운데이션 모델의 한 가지 어려운 점은 이들이 종종 자기회귀적(autoregressive)이다.
    - 자기회귀적이란? 순차적인 데이터(sequence data)를 생성하는 방식
![](https://velog.velcdn.com/images/dkan9634/post/57adcce4-e551-41c7-85c3-a85142106681/image.png)

### 애플리케이션 개발
- 개발 계층은 평가, 프롬프트 엔지니어링, AI 인터페이스 역할로 구성
#### 평가
- 위험을 완화하고 기회를 발견하는 과정
- 모델을 선택하고 진행 상황을 벤치마크하며, 애플리케이션의 배포 준비 여부를 판단하는 데 쓰인다.

#### 프롬프트 엔지니어링 및 컨텍스트 구성
- 프롬프트 엔지니어링은 모델 가중치를 변경하지 않 고 입력만으로 AI 모델에서 원하는 동작을 이끌어 내는 것
- 단순히 모델에게 무엇을 하라고 말하는 것이 아니라 **주어진 작업을 수행하는 데 필요한 컨택스트와 도구를 모델에게 제공하는 것**이다.

#### AI 인터페이스
![](https://velog.velcdn.com/images/dkan9634/post/493b57fb-2f89-4dc8-a92f-8e6f4e78ca48/image.png)

## AI 엔지니어링 vs 풀스택 엔지니어링
- 인터페이스에 대한 강조가 커지면서 AI 엔지니어링은 풀스택 개발에 더 가까워지고 있다.
![](https://velog.velcdn.com/images/dkan9634/post/2f83ef21-be20-4614-b94d-817a7bd84dbc/image.png)
---
# 마치며
이 장의 목적
1. 파운데이션 모델의 등장으로 이제 AI 엔지니어링이 하나의 분야로 자리 잡게 된 것을 설명하는 것
2. 이런 모델을 기반으로 애플리케이션을 만드는 데 필요한 과정으로 전반적으로 설명하는 것

자기 지도 학습이라는 학습 방식 덕분에 언어 모델이 대규모 언어 모델로 발전하게 된 것부터 시작해 언어 모델에 다른 데이터 형태를 통합해 파운데이션 모델이 되는 과정과 파운데이션 모델이 AI 엔지니어링의 등장으로 이어진 과정을 다루었다.



