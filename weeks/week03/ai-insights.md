# Week 03 - AI Engineering 인사이트

각 팀원이 작성한 study-note를 바탕으로 개인별 인사이트와 학습 내용을 정리합니다.

---

## 김성언 (Kim Seong-Eon)

### 핵심 인사이트
- **평가가 AI 애플리케이션 개발의 핵심**: 평가의 목적은 단순히 성능 측정이 아니라 **위험을 줄이고 기회를 발견**하는 것
- **언어 모델링 지표의 이해**: 교차 엔트로피, 퍼플렉시티 등은 모델이 학습 데이터를 얼마나 잘 예측하는지를 보여주며, 모델이 잘 학습할수록 값이 낮아짐
- **평가 주도 개발(EDD)**: 개발 전 평가 기준을 정의하는 것이 투자 대비 효과를 명확히 하는 데 중요

### 독특한 관점 또는 흥미로운 발견
- **퍼플렉시티의 활용**: 퍼플렉시티를 이용해 어떤 텍스트가 모델 학습 데이터에 포함되었는지 탐지할 수 있다는 점이 흥미로움
- **데이터 오염 문제**: 공개 벤치마크가 학습 데이터에 포함되어 평가의 신뢰성이 하락하는 문제를 n-gram 중복이나 퍼플렉시티로 감지할 수 있음
- **심슨의 역설**: 집계된 데이터에서는 모델 A가 좋아 보이지만, 하위 집합에서는 모델 B가 더 좋을 수 있다는 점

### 실무 적용 아이디어
- **구성 요소별 평가**: RAG 시스템 개발 시 PDF 텍스트 추출과 정보 검색을 각각 독립적으로 평가하여 병목 지점 파악
- **데이터 슬라이싱**: 사용자 등급, 트래픽 출처별로 성능을 나눠서 평가하여 특정 세그먼트의 문제 조기 발견
- **평가 파이프라인 자동화**: AI 평가자와 사람 평가를 조합하여 비용 효율적이면서도 신뢰할 수 있는 평가 시스템 구축

### 추가 학습이 필요한 부분
- SAFE(검색 증강 사실성 평가기)의 구체적인 구현 방법
- 텍스트 함의(textual entailment) 모델 학습 및 활용
- 비교 평가에서 순위 알고리즘의 전이성 가정에 대한 수학적 배경

---

## 안태현 (Ahn Tae-Hyun)

### 핵심 인사이트
<!-- 이번 주차 학습에서 가장 중요하다고 생각한 개념이나 내용 -->


### 독특한 관점 또는 흥미로운 발견
<!-- 다른 관점에서 바라본 내용이나 새롭게 발견한 점 -->


### 실무 적용 아이디어
<!-- 실제 업무나 프로젝트에 어떻게 적용할 수 있을지 -->


### 추가 학습이 필요한 부분
<!-- 더 깊이 공부하고 싶은 주제나 이해가 부족한 부분 -->


---

## 이은정 (Lee Eun-Jeong)

### 핵심 인사이트
- **평가의 어려움**: AI 모델이 똑똑해질수록 평가가 더 어려워지며, 개방형 특성 때문에 정답 기반 평가가 더 이상 유효하지 않음
- **AI 평가자의 양면성**: 빠르고 저렴하지만 비일관성, 편향(자기 편향, 첫 위치 편향, 장황성 편향) 등의 한계가 명확함
- **비교 평가의 장점**: 두 출력을 비교하는 것이 각 출력에 구체적인 점수를 매기는 것보다 쉽고, 사람의 선호도를 직접 파악할 수 있음

### 독특한 관점 또는 흥미로운 발견
- **임베딩의 다양한 활용**: 임베딩이 단순히 의미 유사도 측정뿐 아니라 검색, 군집화, 이상 탐지, 데이터 중복 제거 등 다양한 작업에 활용될 수 있다는 점
- **멀티모달 임베딩**: CLIP과 같이 이미지와 텍스트를 하나의 통합 임베딩 공간으로 매핑할 수 있는 기술의 잠재력
- **평가 기준의 모호성**: MLflow, Ragas, LlamaIndex에서 "충실성"이라는 동일한 용어를 사용하지만 지시와 점수 체계가 모두 다르다는 점

### 실무 적용 아이디어
- **턴 기반 vs 작업 기반 평가**: 챗봇 시스템에서 각 턴의 응답 품질과 전체 작업 완수 여부를 모두 평가하여 개선점 파악
- **자체 검증(SelfCheckGPT) 활용**: 비용은 들지만 환각을 감지하는 효과적인 방법으로 중요한 응답에 선택적으로 적용
- **온디바이스 배포 고려**: 인터넷이 불안정한 환경을 위한 서비스 개발 시 오픈소스 모델의 경량화 및 로컬 실행 검토

### 추가 학습이 필요한 부분
- 평가 하네스(evaluation harness)의 실제 구현 및 사용법
- 보상 모델(reward model)과 선호도 모델의 학습 방법론
- 데이터 계보(data lineage)와 저작권 문제에 대한 법적 측면
- 파레토 최적화를 이용한 다목적 모델 선택 방법

---

## 허채연 (Heo Chae-Yeon)

### 핵심 인사이트
- **평가 기준의 명확화**: 좋은 응답이 무엇인지 정의하는 것이 평가에서 가장 어렵고 중요한 부분이며, 정확한 답변이 항상 좋은 응답은 아님
- **사실 일관성의 두 가지 접근**: 국소적 사실 일관성(컨텍스트 기반)과 전역적 사실 일관성(공개 지식 기반)을 구분하여 평가해야 함
- **모델 선택의 복잡성**: 하드 속성과 소프트 속성을 구분하고, 데이터 프라이버시부터 비용, 제어까지 다양한 요소를 균형 있게 고려해야 함

### 독특한 관점 또는 흥미로운 발견
- **AI 평가자 프롬프트의 중요성**: AI 평가자는 단순히 모델만이 아니라 모델과 프롬프트를 포함하는 시스템이며, 언어 모델은 숫자보다 텍스트(분류)를 더 잘 다룸
- **지시 수행 능력과 역할 연기**: 지시 수행이 도메인 능력, 생성 능력과 혼동되기 쉬우며, 역할 연기가 엔터테인먼트뿐 아니라 프롬프트 엔지니어링 기법으로도 활용됨
- **오픈 소스의 격차 축소**: 다양한 벤치마크에서 오픈소스 모델과 독점 모델 간 격차가 좁혀지고 있지만, 사용자 피드백 부족이 오픈소스의 약점

### 실무 적용 아이디어
- **평가 가이드라인 체계화**: 예시와 함께 평가 기준표를 만들고, 해야 할 일뿐만 아니라 하면 안 되는 일도 명확히 정의
- **평가 지표와 비즈니스 지표 연결**: 모델 성능 개선이 실제 비즈니스 목표(매출, 사용자 만족도 등)에 미치는 영향을 정량화
- **모델 API vs 자체 호스팅 의사결정**: 데이터 프라이버시, 성능, 비용, 제어 등을 체계적으로 비교하여 규모에 맞는 선택

### 추가 학습이 필요한 부분
- 구조화된 출력(JSON, regex 형식)을 위한 모델 파인튜닝 방법
- 지식 강화 검증(SAFE)의 실제 구현 및 API 연동
- 부트스트랩을 이용한 평가 안정성 검증 방법
- 로그프롭(log probability)을 활용한 모델 확신도 측정 기법

---

## 통합 토론 주제

스터디 세션에서 함께 논의하면 좋을 질문들을 자유롭게 추가해주세요.

### 공통 질문
- AI 평가자의 편향(자기 편향, 첫 위치 편향, 장황성 편향)을 실무에서 어떻게 완화할 수 있을까?
- 평가 주도 개발(EDD)을 실제 프로젝트에 도입할 때 가장 큰 장애물은 무엇일까?
- 데이터 오염 문제가 점점 심각해지는 상황에서 벤치마크의 신뢰성을 어떻게 유지할 수 있을까?

### 심화 토론
- 비교 평가의 확장성 문제(모델 수의 제곱에 비례)를 해결하기 위한 효율적인 샘플링 전략은?
- 오픈소스 모델이 사용자 피드백 부족 문제를 극복하고 독점 모델을 따라잡을 수 있을까?
- 사실 일관성 평가에서 "무엇이 사실인가"에 대한 출처 신뢰성을 어떻게 판단해야 할까?
- 평가 파이프라인의 비용과 정확성 사이의 트레이드오프를 어떻게 최적화할 수 있을까?

### 다음 주차 연결 포인트
- 5장(프롬프트 엔지니어링)과 연결: 역할 연기, 지시 수행 능력을 향상시키는 프롬프트 기법
- 6장(RAG/Agents)과 연결: 사실 일관성 평가가 RAG 시스템에서 특히 중요한 이유
- 평가 기준 정의 → 프롬프트 최적화 → RAG 구축의 전체 파이프라인 이해
